# Устранение неполадок

## Ошибка: `ValueError: OPENAI_API_KEY environment variable not set`

### Проблема

При запуске приложения возникала следующая ошибка:

```
ValueError: OPENAI_API_KEY environment variable not set for OpenAI provider.
```

Это происходило потому, что приложение по умолчанию пыталось использовать API от OpenAI, для которого требуется ключ `OPENAI_API_KEY`. Однако, целью была работа с локальной языковой моделью.

### Решение

Проблема была решена изменением провайдера по умолчанию с `"openai"` на `"local"` в файле `src/document_search/llm_client.py`.

**Изменение в коде:**

Была изменена строка:
```python
llm_provider = os.getenv("LLM_PROVIDER", "openai").lower()
```
на:
```python
llm_provider = os.getenv("LLM_PROVIDER", "local").lower()
```

Это изменение гарантирует, что приложение по умолчанию использует локальный сервер, совместимый с API OpenAI (например, LM Studio), и не требует наличия ключа `OPENAI_API_KEY` для запуска в режиме локальной разработки.

---

## Проблемы с очисткой шапок PDF

### Проблема 1: Шапки не удаляются из документов

После повторной индексации вы все еще видите текст из шапок в результатах поиска.

**Возможные причины и решения:**

1.  **Неточный шаблон:** Текст "меток" в файле `header_templates.json` не полностью совпадает с текстом в PDF. Даже лишний пробел имеет значение.
    *   **Решение:** Убедитесь, что строки в `header_labels` точно соответствуют тексту, который извлекается из PDF.

2.  **Индекс не был обновлен:** Вы изменили `header_templates.json`, но не запустили заново скрипт индексации (`scripts/run_indexing.py`).
    *   **Решение:** После **любого** изменения в логике извлечения текста или в шаблонах необходимо полностью перезапускать индексацию.

3.  **Неверный формат JSON:** Файл `header_templates.json` содержит синтаксическую ошибку (например, пропущенную запятую).
    *   **Решение:** Проверьте файл в любом онлайн-валидаторе JSON. При запуске `run_indexing.py` в консоли также может появиться сообщение об ошибке.

### Проблема 2: Удаляется слишком много текста (часть полезного контента)

В результатах поиска отсутствуют фрагменты, которые должны были там быть, особенно из начала страниц.

**Возможные причины и решения:**

1.  **Слишком "жадный" шаблон:** Одна из меток в `header_labels` слишком общая и случайно совпадает с началом обычного абзаца в тексте.
    *   **Решение:** Просмотрите список `header_labels` и сделайте метки как можно более специфичными.

2.  **Агрессивный "запас" на удаление:** Внутренняя логика в `ingest.py` удаляет 5 строк после нахождения последней метки. Возможно, это слишком много.
    *   **Решение:** В файле `src/document_search/ingest.py` внутри функции `_clean_page_text` есть строка `content_start_index = last_header_line_index + 5`. Можно попробовать уменьшить `5` до `3` или `2`. После изменения не забудьте заново запустить индексацию.