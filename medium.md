# **–ó–∞–≥–æ–ª–æ–≤–æ–∫:** –°–æ–∑–¥–∞–µ–º —Å –Ω—É–ª—è "—É–º–Ω—ã–π" –ø–æ–∏—Å–∫ –ø–æ PDF-–¥–æ–∫—É–º–µ–Ω—Ç–∞–º: –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –Ω–∞ Python

**–ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ (–î–µ–∫):** –ü–æ—à–∞–≥–æ–≤–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é RAG-—Å–∏—Å—Ç–µ–º—ã –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º, —Å —Ä–µ—à–µ–Ω–∏–µ–º —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–æ–±–ª–µ–º—ã –æ—á–∏—Å—Ç–∫–∏ "–≥—Ä—è–∑–Ω—ã—Ö" –¥–∞–Ω–Ω—ã—Ö.

**TL;DR:**
*   –ü–æ—Å—Ç—Ä–æ–∏–º –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π RAG-–ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –≤–∞—à–∏–º PDF-—Ñ–∞–π–ª–∞–º.
*   –†–µ–∞–ª–∏–∑—É–µ–º "—É–º–Ω—ã–π" –º–µ—Ö–∞–Ω–∏–∑–º –æ—á–∏—Å—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —à–∞–ø–æ–∫ –∏ –ø–æ–¥–≤–∞–ª–æ–≤.
*   –ù–∞—Å—Ç—Ä–æ–∏–º –≤–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å: –æ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–æ –∑–∞–ø—É—Å–∫–∞ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –Ω–∞ Streamlit.
*   –†–∞–∑–±–µ—Ä–µ–º —Ç–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏ —Å–ø–æ—Å–æ–±—ã –∏—Ö —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –æ–ø—ã—Ç–∞.
*   –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ –Ω–∞ –≤–∞—à–µ–º –∫–æ–º–ø—å—é—Ç–µ—Ä–µ.

---

## 1. –ë–æ–ª—å, –∑–Ω–∞–∫–æ–º–∞—è –∫–∞–∂–¥–æ–º—É: –ø–æ—á–µ–º—É Ctrl+F –±–æ–ª—å—à–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
**–ü—Ä–æ–±–ª–µ–º–∞:** –£ –≤–∞—Å –¥–µ—Å—è—Ç–∫–∏ PDF-—Ñ–∞–π–ª–æ–≤ ‚Äî —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤, –¥–æ–≥–æ–≤–æ—Ä–æ–≤, –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π. –ù–∞–π—Ç–∏ –≤ –Ω–∏—Ö –Ω—É–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é ‚Äî –º—É—á–µ–Ω–∏–µ. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–∏—Å–∫ –∏—â–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏ –Ω–µ –ø–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

**–†–µ—à–µ–Ω–∏–µ:** –ú—ã –ø–æ—Å—Ç—Ä–æ–∏–º —Å–∏—Å—Ç–µ–º—É, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–Ω–∏–º–∞–µ—Ç *—Å–º—ã—Å–ª* –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –≠—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫, –∏ –≤ –µ–≥–æ –æ—Å–Ω–æ–≤–µ –ª–µ–∂–∏—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ RAG (Retrieval-Augmented Generation).


## 2. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–∞—à–µ–≥–æ –ø–æ–∏—Å–∫–æ–≤–∏–∫–∞ (RAG-–ø–∞–π–ø–ª–∞–π–Ω)
–ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ, —á—Ç–æ —Ç–∞–∫–æ–µ RAG.
RAG (Retrieval-Augmented Generation) ‚Äî —ç—Ç–æ –ø–æ–¥—Ö–æ–¥, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º –ò–ò —Å–Ω–∞—á–∞–ª–∞ –∏—â–µ—Ç –Ω—É–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –±–∞–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –∞ –ø–æ—Ç–æ–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –µ—ë –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ü—Ä–æ—â–µ: –º–æ–¥–µ–ª—å –Ω–µ ¬´–≤—Å—ë –∑–Ω–∞–µ—Ç —Å–∞–º–∞¬ª, –∞ —É–º–µ–µ—Ç –±—ã—Å—Ç—Ä–æ –Ω–∞—Ö–æ–¥–∏—Ç—å –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω—É–∂–Ω—ã–µ –∫—É—Å–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤.

**–í–∏–∑—É–∞–ª—å–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ó–¥–µ—Å—å –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥–æ–π–¥–µ—Ç –¥–∏–∞–≥—Ä–∞–º–º–∞, –ø–æ–∫–∞–∑—ã–≤–∞—é—â–∞—è 6 —à–∞–≥–æ–≤:

1.  **Ingest (–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ):** –ß–∏—Ç–∞–µ–º "—Å—ã—Ä–æ–π" —Ç–µ–∫—Å—Ç –∏–∑ PDF.
2.  **Clean (–û—á–∏—Å—Ç–∫–∞):** *<-- –ù–∞—à —Å–µ–∫—Ä–µ—Ç–Ω—ã–π –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç!* –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —à–∞–ø–∫–∏, —á—Ç–æ–±—ã –Ω–µ "–∑–∞—Å–æ—Ä—è—Ç—å" –º–æ–¥–µ–ª—å.
3.  **Chunk (–†–∞–∑–±–∏–µ–Ω–∏–µ):** –î–µ–ª–∏–º —Ç–µ–∫—Å—Ç –Ω–∞ –Ω–µ–±–æ–ª—å—à–∏–µ, –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã (—á–∞–Ω–∫–∏).
4.  **Embed (–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è):** –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –∫–∞–∂–¥—ã–π —á–∞–Ω–∫ –≤ —á–∏—Å–ª–æ–≤–æ–π –≤–µ–∫—Ç–æ—Ä —Å –ø–æ–º–æ—â—å—é AI-–º–æ–¥–µ–ª–∏.
5.  **Index (–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è):** –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä—ã –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (FAISS) –¥–ª—è –º–æ–ª–Ω–∏–µ–Ω–æ—Å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.
6.  **Search & Generate (–ü–æ–∏—Å–∫ –∏ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è):** –ù–∞—Ö–æ–¥–∏–º –ø–æ –∑–∞–ø—Ä–æ—Å—É —Å–∞–º—ã–µ –±–ª–∏–∑–∫–∏–µ –ø–æ —Å–º—ã—Å–ª—É –≤–µ–∫—Ç–æ—Ä—ã –∏ –æ—Ç–¥–∞–µ–º –∏—Ö —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (LLM) –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.

### 2.1 Ingest + Clean
–ö–ª—é—á: –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏ —É–±—Ä–∞—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —à–∞–ø–∫–∏ —Å–æ 2-–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –¥–∞–ª–µ–µ –ø–æ —à–∞–±–ª–æ–Ω–∞–º –∏–∑ `header_templates.json`.

```1:92:/Users/j15/Documents/Code_and_Scripts_local/AI-Powered Document Search/src/document_search/ingest.py
"""
–ú–æ–¥—É–ª—å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF-—Ñ–∞–π–ª–æ–≤.

–§—É–Ω–∫—Ü–∏—è `extract_text_from_pdfs` —Å–∫–∞–Ω–∏—Ä—É–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—É—é –ø–∞–ø–∫—É, –Ω–∞—Ö–æ–¥–∏—Ç –≤—Å–µ
—Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .pdf, –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –∏—Ö —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ PyMuPDF (fitz)
–∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü.

–î–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü, –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–π, –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –æ—á–∏—Å—Ç–∫–∞ –æ—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —à–∞–ø–æ–∫.
–õ–æ–≥–∏–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —à–∞–±–ª–æ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞ `header_templates.json`.
"""
import fitz
import os
import json

def _clean_page_text(page_text: str, header_labels: list[str]) -> str:
    """
    –û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ç —à–∞–ø–∫–∏.

    –ê–ª–≥–æ—Ä–∏—Ç–º –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Ö–æ–∂–∞ –Ω–∞ –º–µ—Ç–∫—É –∏–∑ —à–∞–ø–∫–∏,
    –∏ —É–¥–∞–ª—è–µ—Ç –≤–µ—Å—å —Ç–µ–∫—Å—Ç –¥–æ —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏, –≤–∫–ª—é—á–∞—è –Ω–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å, 
    —á—Ç–æ–±—ã –∑–∞—Ö–≤–∞—Ç–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.
    """
    lines = page_text.split('\n')
    last_header_line_index = -1

    # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –æ–¥–Ω–æ–π –∏–∑ –º–µ—Ç–æ–∫
    for i, line in enumerate(lines):
        stripped_line = line.strip()
        if any(stripped_line.startswith(label) for label in header_labels):
            last_header_line_index = i

    # –ï—Å–ª–∏ –º–µ—Ç–∫–∏ —à–∞–ø–∫–∏ –≤–æ–æ–±—â–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
    if last_header_line_index == -1:
        return page_text

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –≥–¥–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç.
    # –ë–µ—Ä–µ–º –∏–Ω–¥–µ–∫—Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –º–µ—Ç–∫–∏ + –Ω–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, 5 —Å—Ç—Ä–æ–∫),
    # —á—Ç–æ–±—ã –ø–æ–∫—Ä—ã—Ç—å –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏.
    content_start_index = last_header_line_index + 5

    # –°–æ–±–∏—Ä–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
    cleaned_lines = lines[content_start_index:]
    
    return '\n'.join(cleaned_lines)


def extract_text_from_pdfs(folder: str) -> list[dict]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö PDF-—Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ, –æ—á–∏—â–∞—è —à–∞–ø–∫–∏.
    """
    try:
        with open('header_templates.json', 'r', encoding='utf-8') as f:
            templates = json.load(f)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π —à–∞–±–ª–æ–Ω –∏–∑ —Ñ–∞–π–ª–∞
        header_labels = templates['templates'][0]['header_labels']
    except FileNotFoundError:
        print("‚ö†Ô∏è  –§–∞–π–ª 'header_templates.json' –Ω–µ –Ω–∞–π–¥–µ–Ω. –û—á–∏—Å—Ç–∫–∞ —à–∞–ø–æ–∫ –Ω–µ –±—É–¥–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å—Å—è.")
        header_labels = []
    except (json.JSONDecodeError, IndexError, KeyError):
        print("‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è 'header_templates.json'. –§–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥–µ–Ω –∏–ª–∏ –∏–º–µ–µ—Ç –Ω–µ–≤–µ—Ä–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É.")
        header_labels = []


    documents = []
    for file in os.listdir(folder):
        if file.endswith(".pdf"):
            path = os.path.join(folder, file)
            full_text = ""
            try:
                pdf = fitz.open(path)
                for i, page in enumerate(pdf):
                    page_text = page.get_text()
                    if i == 0 or not header_labels:
                        # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞–∫ –µ—Å—Ç—å –∏–ª–∏ –µ—Å–ª–∏ –Ω–µ—Ç –º–µ—Ç–æ–∫
                        full_text += page_text
                    else:
                        # –û—á–∏—â–∞–µ–º –≤—Å–µ –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                        cleaned_text = _clean_page_text(page_text, header_labels)
                        full_text += cleaned_text
                pdf.close()
                documents.append({"filename": file, "text": full_text})
                print(f"‚úÖ {file} - {len(full_text)} chars")
            except Exception as e:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª {file}: {e}")

    return documents

if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    docs = extract_text_from_pdfs("pdfs")
```

### 2.2 Chunk
–†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è —á–∞–Ω–∫–∏.

```1:25:/Users/j15/Documents/Code_and_Scripts_local/AI-Powered Document Search/src/document_search/chunk.py
"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ –±–æ–ª–µ–µ –º–µ–ª–∫–∏–µ —á–∞—Å—Ç–∏ (—á–∞–Ω–∫–∏).

–§—É–Ω–∫—Ü–∏—è `chunk_document` –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –∏ –¥–µ–ª–∏—Ç –µ–≥–æ –Ω–∞ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è
—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞. –≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –±–æ–ª—å—à–∏–µ
–¥–æ–∫—É–º–µ–Ω—Ç—ã –º–æ–∂–Ω–æ –±—ã–ª–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å.
"""
def chunk_document(doc, size=1000, overlap=200):
    text = doc["text"]
    chunks = []
    start = 0
    while start < len(text):
        end = start + size
        chunk = text[start:end]
        chunks.append({"filename": doc["filename"], "text": chunk})
        start += size - overlap
    return chunks

if __name__ == "__main__":
    from .ingest import extract_text_from_pdfs
    docs = extract_text_from_pdfs("./pdfs")
    all_chunks = []
    for doc in docs:
        all_chunks.extend(chunk_document(doc))
    print(f"üîπ Created {len(all_chunks)} chunks")
```

### 2.3 Embed
–°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å –ø–æ–º–æ—â—å—é `sentence-transformers`.

```1:23:/Users/j15/Documents/Code_and_Scripts_local/AI-Powered Document Search/src/document_search/embed.py
"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è (—ç–º–±–µ–¥–¥–∏–Ω–≥–∏).

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å `all-MiniLM-L6-v2` –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ sentence-transformers
–¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ —á–∏—Å–ª–æ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞—Ç–µ–º
–º–æ–≥—É—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞.
"""
from sentence_transformers import SentenceTransformer
import numpy as np

model = SentenceTransformer('all-MiniLM-L6-v2')

def embed_chunks(chunks):
    texts = [c["text"] for c in chunks]
    vectors = model.encode(texts)
    return np.array(vectors)

if __name__ == "__main__":
    import pickle
    with open("chunks.pkl", "rb") as f:
        all_chunks = pickle.load(f)
    vectors = embed_chunks(all_chunks)
    print(f"‚úÖ Embedded shape: {vectors.shape}")
```

### 2.4 Index
–°—Ç—Ä–æ–∏–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º FAISS-–∏–Ω–¥–µ–∫—Å.

```1:27:/Users/j15/Documents/Code_and_Scripts_local/AI-Powered Document Search/src/document_search/index.py
"""
–ú–æ–¥—É–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ FAISS.

–§—É–Ω–∫—Ü–∏—è `build_faiss_index` —Å—Ç—Ä–æ–∏—Ç –∏–Ω–¥–µ–∫—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
—Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤. –ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä—ã –∏ —á–∞–Ω–∫–∏,
—Å–æ–∑–¥–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–≥–æ –≤–º–µ—Å—Ç–µ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ (—á–∞–Ω–∫–∞–º–∏) –Ω–∞ –¥–∏—Å–∫.
"""
import faiss
import pickle
import numpy as np

def build_faiss_index(vectors):
    dim = vectors.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(vectors)
    return index

if __name__ == "__main__":
    with open("vectors.npy", "rb") as f:
        vectors = np.load(f)
    with open("chunks.pkl", "rb") as f:
        all_chunks = pickle.load(f)
    index = build_faiss_index(vectors)
    faiss.write_index(index, "docs.index")
    with open("chunks.pkl", "wb") as f:
        pickle.dump(all_chunks, f)
    print("üì¶ Index and metadata saved")
```

### 2.5 Search
–í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ `top_k` —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.

```1:26:/Users/j15/Documents/Code_and_Scripts_local/AI-Powered Document Search/src/document_search/search.py
"""
–ú–æ–¥—É–ª—å –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º.

–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å FAISS –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–æ–≤.
–§—É–Ω–∫—Ü–∏—è `search_docs` –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å, –∫–æ–¥–∏—Ä—É–µ—Ç –µ–≥–æ –≤ –≤–µ–∫—Ç–æ—Ä
–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ `top_k` –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.
"""
import pickle
import faiss
from sentence_transformers import SentenceTransformer
import numpy as np

model = SentenceTransformer('all-MiniLM-L6-v2')
index = faiss.read_index("docs.index")
with open("chunks.pkl", "rb") as f:
    chunks = pickle.load(f)

def search_docs(query, top_k=3):
    q_vector = model.encode([query])
    distances, indices = index.search(np.array(q_vector), top_k)
    return [chunks[i] for i in indices[0]]

if __name__ == "__main__":
    results = search_docs("Explain transfer learning")
    for r in results:
        print(f"{r['filename']} :\n{r['text'][:300]}...\n")
```

### 2.6 Generate
–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM-–∫–ª–∏–µ–Ω—Ç.

```1:30:/Users/j15/Documents/Code_and_Scripts_local/AI-Powered Document Search/src/document_search/generate.py
"""
–ú–æ–¥—É–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç llm_client –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ –∏ –º–æ–¥–µ–ª–∏.
"""
from .llm_client import get_llm_client_and_model

# –ü–æ–ª—É—á–∞–µ–º –∫–ª–∏–µ–Ω—Ç –∏ –∏–º—è –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥—É–ª—è
client, model_name = get_llm_client_and_model()

def ask(question, context):
    prompt = f"""
Context:
{context}
Question: {question}
Answer in a short paragraph.
"""
    response = client.chat.completions.create(
        model=model_name,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
    )
    return response.choices[0].message.content

if __name__ == "__main__":
    from .search import search_docs
    question = "Explain transfer learning"
    top_chunks = search_docs(question)
    context = "\n\n".join([c["text"] for c in top_chunks])
    answer = ask(question, context)
    print("üí° Answer:", answer)
```

## 3. –ö–∞–∫ —ç—Ç–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å: –ø–æ—à–∞–≥–æ–≤–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
**–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è:**
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Python 3.10+ –∏ —Å–æ–∑–¥–∞–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: `pip install -r requirements.txt`
- –ü–æ–º–µ—Å—Ç–∏—Ç–µ PDF-—Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É `pdfs/`

**–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è (–µ–¥–∏–Ω—ã–º —Å–∫—Ä–∏–ø—Ç–æ–º):**
- –í—ã–ø–æ–ª–Ω–∏—Ç–µ: `python scripts/run_indexing.py`
  - –°–∫—Ä–∏–ø—Ç –ø—Ä–æ–π–¥–µ—Ç 4 —à–∞–≥–∞: Extract ‚Üí Chunk ‚Üí Embed ‚Üí Index

**–ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞:**
- –í—ã–ø–æ–ª–Ω–∏—Ç–µ: `streamlit run app.py`
- –û—Ç–∫—Ä–æ–π—Ç–µ `http://localhost:8501`
**–í–∏–∑—É–∞–ª—å–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –°–∫—Ä–∏–Ω—à–æ—Ç —Ä–∞–±–æ—Ç–∞—é—â–µ–≥–æ –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.

## 4. –ì–ª—É–±–æ–∫–æ–µ –ø–æ–≥—Ä—É–∂–µ–Ω–∏–µ: –±–æ—Ä–µ–º—Å—è —Å "—à—É–º–æ–º" –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
–≠—Ç–æ –∫–ª—é—á–µ–≤–∞—è, –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å —Å—Ç–∞—Ç—å–∏.

**–ü—Ä–æ–±–ª–µ–º–∞:** –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä "—Å—ã—Ä–æ–≥–æ" —Ç–µ–∫—Å—Ç–∞ —Å–æ –≤—Ç–æ—Ä–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã PDF, –≥–¥–µ –≤–∏–¥–Ω–∞ —à–∞–ø–∫–∞. –û–±—ä—è—Å–Ω–∏—Ç—å, –ø–æ—á–µ–º—É —ç—Ç–æ –ø–ª–æ—Ö–æ: –∏—Å–∫–∞–∂–∞–µ—Ç —Å–º—ã—Å–ª —á–∞–Ω–∫–æ–≤, —Ç—Ä–∞—Ç–∏—Ç –¥—Ä–∞–≥–æ—Ü–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç LLM.

**–†–µ—à–µ–Ω–∏–µ:** –†–∞—Å—Å–∫–∞–∑–∞—Ç—å –æ –Ω–∞—à–µ–º –ø–æ–¥—Ö–æ–¥–µ —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º —Ñ–∞–π–ª–æ–º `header_templates.json`.

**–ü–æ–∫–∞–∑–∞—Ç—å –∫–æ–¥:**
*   –ü—Ä–∏–≤–µ—Å—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ `header_templates.json` –∏ –æ–±—ä—è—Å–Ω–∏—Ç—å, —á—Ç–æ —Å—é–¥–∞ –Ω—É–∂–Ω–æ –≤–Ω–æ—Å–∏—Ç—å —Ç–æ–ª—å–∫–æ "–º–µ—Ç–∫–∏" —à–∞–ø–∫–∏.
*   –ü–æ–∫–∞–∑–∞—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∫–æ–¥–∞ –∏–∑ `src/document_search/ingest.py` (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü), —á—Ç–æ–±—ã –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å, –∫–∞–∫ –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è.

**–í—ã–≤–æ–¥:** –≠—Ç–æ—Ç —à–∞–≥ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å "–∏–≥—Ä—É—à–µ—á–Ω—ã–π" –ø—Ä–æ–µ–∫—Ç –≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –≥–æ—Ç–æ–≤—ã–π –∫ —Ä–∞–±–æ—Ç–µ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏, –Ω–µ—Å–æ–≤–µ—Ä—à–µ–Ω–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏.

## 5. –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫? –†–∞–∑–±–æ—Ä —Ç–∏–ø–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º (–¢—Ä–∞–±–ª—à—É—Ç–∏–Ω–≥)
(–≠—Ç–æ—Ç —Ä–∞–∑–¥–µ–ª –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –Ω–∞—à–µ–º —Ñ–∞–π–ª–µ `TROUBLESHOOTING.md`).

*   **–ü—Ä–æ–±–ª–µ–º–∞ 1: "–Ø –∑–∞–ø—É—Å—Ç–∏–ª –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é, –Ω–æ —à–∞–ø–∫–∏ –≤—Å–µ —Ä–∞–≤–Ω–æ –≤–∏–¥–Ω—ã –≤ –ø–æ–∏—Å–∫–µ!"**
    *   *–†–µ—à–µ–Ω–∏—è:* –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ—á–Ω–æ—Å—Ç—å –º–µ—Ç–æ–∫ –≤ JSON; —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã *–ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏–ª–∏* –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
*   **–ü—Ä–æ–±–ª–µ–º–∞ 2: "–ò–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –ø—Ä–æ–ø–∞–¥–∞–µ—Ç –ø–æ–ª–µ–∑–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–∞–Ω–∏—Ü!"**
    *   *–†–µ—à–µ–Ω–∏—è:* –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –Ω–µ —Å–ª–∏—à–∫–æ–º –ª–∏ –æ–±—â–∏–µ —É –≤–∞—Å –º–µ—Ç–∫–∏ –≤ JSON; –ø–æ–∫–∞–∂–∏—Ç–µ, –≥–¥–µ –≤ –∫–æ–¥–µ `ingest.py` –º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å "–∑–∞–ø–∞—Å" —É–¥–∞–ª—è–µ–º—ã—Ö —Å—Ç—Ä–æ–∫.
*   **–ü—Ä–æ–±–ª–µ–º–∞ 3: "–û—à–∏–±–∫–∞ –ø—Ä–æ `OPENAI_API_KEY` –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"**
    *   *–†–µ—à–µ–Ω–∏–µ:* –†–∞—Å—Å–∫–∞–∑–∞—Ç—å, –∫–∞–∫ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –≤ `llm_client.py`.

## 6. –ß—Ç–æ –¥–∞–ª—å—à–µ? –ü—É—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è
(–í–∑—è—Ç—å –∏–∑ `agents.md` "–í–æ–∑–º–æ–∂–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è").

–ö—Ä–∞—Ç–∫–æ –ø–µ—Ä–µ—á–∏—Å–ª–∏—Ç—å 3-4 –∏–¥–µ–∏:
*   –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –æ–±–ª–∞—á–Ω—É—é –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö (Pinecone, Qdrant).
*   –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–≤–µ–∫—Ç–æ—Ä–Ω—ã–π + –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º).
*   –î–æ–±–∞–≤–ª–µ–Ω–∏–µ re-ranking'–∞ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏.

---
**–ó–∞–∫–ª—é—á–µ–Ω–∏–µ:**
–ö—Ä–∞—Ç–∫–∏–π –∏—Ç–æ–≥: "–ú—ã –Ω–µ –ø—Ä–æ—Å—Ç–æ —Å–æ–∑–¥–∞–ª–∏ –ø–æ–∏—Å–∫–æ–≤–∏–∫, –∞ —Ä–µ—à–∏–ª–∏ —Ä–µ–∞–ª—å–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è 80% —Ä–∞–±–æ—Ç—ã –≤ –ª—é–±–æ–º AI-–ø—Ä–æ–µ–∫—Ç–µ".

**–ü—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é (CTA):** "–ï—Å–ª–∏ —ç—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –±—ã–ª–æ –ø–æ–ª–µ–∑–Ω—ã–º, –ø–æ—Å—Ç–∞–≤—å—Ç–µ –∑–≤–µ–∑–¥—É –Ω–∞ GitHub! –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –∏–¥–µ–∏ –∏–ª–∏ –≤—ã –Ω–∞—à–ª–∏ –æ—à–∏–±–∫—É, —Å–æ–∑–¥–∞–≤–∞–π—Ç–µ issue. –£–¥–∞—á–∏ –≤ –≤–∞—à–∏—Ö –ø—Ä–æ–µ–∫—Ç–∞—Ö!"

---
**–¢–µ–≥–∏ –¥–ª—è Medium:**
`Python`, `Artificial Intelligence`, `LLM`, `RAG`, `Data Science`